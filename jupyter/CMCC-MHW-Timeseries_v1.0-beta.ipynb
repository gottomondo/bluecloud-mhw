{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab134e0-c306-47f3-b57b-db115a9c4e24",
   "metadata": {},
   "source": [
    "# MHW Notebook: TimeSeries\n",
    "**Version**: v1.0-beta \n",
    "\n",
    "**Last update**: 2025-01-31\n",
    "\n",
    "**Authors**: ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e55053a-acc8-46d1-991d-57d6a8cfbb41",
   "metadata": {},
   "source": [
    "This notebook is designed for the operational analysis of Marine Heatwave (MHW) detection in the Mediterranean Sea by comparing climatological baselines to Sea Surface Temperature (SST) data from reprocessed (REP) or near-real-time (NRT) satellite observations, as well as model forecast data (MFS). It connects to the Copernicus Marine Service (CMEMS) via the copernicusmarine API.\n",
    "\n",
    "Data is area-averaged using grid cell areas and visualized as a time series plot to enhance the detection and analysis of MHW events. Efficient processing of large spatial datasets is enabled by xarray and numpy, while the wavesnspikes algorithm supports real-time heatwave detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ab351-6e99-418c-996f-ea235dcadfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, time, warnings\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from wavesnspikes import wns\n",
    "import copernicusmarine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # Ignore all warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785700b3-661d-49c8-81e2-9d172221158e",
   "metadata": {},
   "source": [
    "### 1. Select the CMEMS dateset of interest\n",
    "- Mediterranean Satellite Reprocessed (REP) Sea Surface Temperature (SST) with data from 1982\n",
    "- Mediterranean Satellite Near Real Time SST (NRT) with data from 2008\n",
    "- ~~Model Mediterranean Forecasting System (MFS) that provides daily forecasts of oceanic variables from most recent years and 10 days forecast~~ (not yet available)\n",
    "\n",
    "- Climatology data: Long-term averages (from 1987â€“2021) to provide a baseline for comparing the CMEMS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb79924-ad4f-4725-8b76-ff927395618d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CMEMS products metadata\n",
    "CMEMS_datasets_options = {'cmems_SST_MED_SST_L4_REP_OBSERVATIONS_010_021':{'varname':  \"analysed_sst\", \"prod_type\": 'REP',\n",
    "                                                                         'grid_file':\"prev/cell_areas_CMS.nc\",\n",
    "                                                                         'clim_file':\"CMS_SST_Climatology_19872021.nc\",\n",
    "                                                                         'region_folder':'prev'},\n",
    "                        'SST_MED_SST_L4_NRT_OBSERVATIONS_010_004_a_V2': {'varname':  \"analysed_sst\", \"prod_type\": 'NRT',\n",
    "                                                                         'grid_file':\"2024/cell_areas_CMS_NRT.nc\",\n",
    "                                                                         'clim_file':\"CMS_SST_Climatology_19872021_rect00625.nc\",\n",
    "                                                                         'region_folder':'2024'},\n",
    "                        # 'cmems_mod_med_phy-tem_anfc_4.2km_P1D-m':       {'varname':  \"thetao\", \"prod_type\": 'MFS',\n",
    "                        #                                                  'grid_file':\"MFS_CMS/cell_areas_MFS_CMS.nc\",\n",
    "                        #                                                  'clim_file':\"MEDREA_Climatology_19872021.nc\",\n",
    "                        #                                                  'region_folder':'MFS_CMS'}\n",
    "                        }\n",
    "\n",
    "\n",
    "# CMEMS datasets selection\n",
    "print('Please select a Copernicus Marine Service (CMEMS) dataset:')\n",
    "datasets_dropdown = widgets.Dropdown(options = CMEMS_datasets_options.keys(), description = 'Dataset:', disabled = False)\n",
    "display(datasets_dropdown) # Display the dropdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fe041-51b3-4d8e-9eb8-b94f713fed11",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Paths Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3058f1-dfa0-4ce0-9b75-8fdcf1486d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# areas and grids\n",
    "area_path = os.path.expanduser(\"~/blue-cloud-dataspace/MEI/CMCC/MHW/input/area/\")\n",
    "# area_path = \"/workspace/VREFolders/MarineEnvironmentalIndicators/input_datasets/mhw/area\"\n",
    "# climatologies\n",
    "clim_path = os.path.expanduser(\"~/blue-cloud-dataspace/MEI/CMCC/MHW/input/clim/\")\n",
    "# clim_path = \"/workspace/VREFolders/MarineEnvironmentalIndicators/input_datasets/mhw/clim\"\n",
    "# regions\n",
    "reg_path  = os.path.expanduser(\"~/blue-cloud-dataspace/MEI/CMCC/MHW/input/region/\")\n",
    "region_files = os.listdir(os.path.join(reg_path,\"MFS_CMS\"))\n",
    "\n",
    "out_dir   = \"/workspace/MHW_figures/TimeSeries/\"\n",
    "os.makedirs(out_dir, exist_ok=True) # Check if the directory exists; create it if it doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af937d75-0907-43e8-bd67-21031637cf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MHW settings\n",
    "time_dim  = 'time'\n",
    "ndays_min = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5755fc3-2763-4432-8b25-74ebca027730",
   "metadata": {},
   "source": [
    "### 2. Load and set\n",
    "- Query copernicusmarine api for selected dataset\n",
    "- Open climatology dataset\n",
    "- Select date of interest\n",
    "- Select region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af8aee-2617-4a48-87ab-ed2decba592e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_id = datasets_dropdown.value\n",
    "varname    = CMEMS_datasets_options[dataset_id]['varname']\n",
    "prod       = CMEMS_datasets_options[dataset_id]['prod_type']\n",
    "print('Selected dataset -> %s'%(dataset_id))\n",
    "\n",
    "# Querying copernicusmarine api\n",
    "print(\"Querying copernicusmarine api...\")\n",
    "t0=time.time()\n",
    "params = {\"credentials_file\": \"bc2026_copernicusmarine-credentials\",\n",
    "          \"dataset_id\": dataset_id, \"variables\" : [varname], \"maximum_depth\": 1.5,}\n",
    "if prod == 'MFS': params[\"minimum_longitude\"] = -6 # this limit is set because of the grid of the available region masks \n",
    "cms_rawdataset = copernicusmarine.open_dataset(**params)\n",
    "print('\\tElapsed time: %ss'%(round(time.time()-t0,1)))\n",
    "\n",
    "# Setting the date range\n",
    "date_min = datetime.utcfromtimestamp(min(cms_rawdataset[time_dim].values).astype('datetime64[s]').astype(int)).date()\n",
    "date_max = datetime.utcfromtimestamp(max(cms_rawdataset[time_dim].values).astype('datetime64[s]').astype(int)).date()\n",
    "start_datepicker = widgets.DatePicker(description='Start', disabled=False, value=date_max-timedelta(ndays_min), min=date_min, max=date_max)\n",
    "end_datepicker   = widgets.DatePicker(description='End', disabled=False, value=date_max, min=date_min, max=date_max)\n",
    "print('\\nPlease select the date range:\\nLimits of the dataset -> from %s to %s' %(date_min, date_max))\n",
    "display(start_datepicker)\n",
    "display(end_datepicker)\n",
    "\n",
    "# Setting the boundary method\n",
    "print('Please select a boundary method (box or regions):')\n",
    "boundary_dropdown = widgets.Dropdown(options=['Rectangle Box','Pre-defined regions'], description='Method:', disabled=False)\n",
    "display(boundary_dropdown) # Display the dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368cd4c-7e1b-43ee-a106-6524b24874d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Climatology and grid area file\n",
    "print(\"\\nOpening cell area...\")\n",
    "t0=time.time()\n",
    "area_rawdataset = area_clim_rawdataset = xr.open_dataset(os.path.join(area_path,CMEMS_datasets_options[dataset_id]['grid_file']))\n",
    "print(f\"\\tDone ({time.time() - t0:.1f}s).\")\n",
    "print(\"\\nOpening climatology files...\")\n",
    "t0=time.time()\n",
    "clim_rawdataset = xr.open_dataset(os.path.join(clim_path,CMEMS_datasets_options[dataset_id]['clim_file']))\n",
    "if prod == 'MFS': area_clim_rawdataset = xr.open_dataset(os.path.join(area_path,\"MFS/cell_areas_MEDREA.nc\")) # climatology and MFS on different grids\n",
    "print(f\"\\tDone ({time.time() - t0:.1f}s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ef1c6-9f51-480c-a516-3ac114b7b0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dates check\n",
    "date_start = start_datepicker.value\n",
    "date_end   = end_datepicker.value \n",
    "if (date_end-date_start).days < ndays_min:\n",
    "    print('Minimum range of %s days not respected OR Start date is after End date.\\nSetting Start date to %s days before End date.'%(ndays_min,ndays_min))\n",
    "    date_start = date_end - timedelta(ndays_min)\n",
    "print('\\nDate range: %s to %s\\n'%(date_start,date_end))\n",
    "\n",
    "# Boundary check\n",
    "print('Boundary method selected -> %s'%boundary_dropdown.value)\n",
    "filter_by_box = False\n",
    "if boundary_dropdown.value == 'Rectangle Box':\n",
    "    filter_by_box = True\n",
    "    print('\\nInsert the coordinates of the region of interest:\\nThe standard values are the dataset limits.')\n",
    "    n_dec = 3\n",
    "    lon_min, lon_max = np.round(cms_rawdataset.longitude.min().item(),n_dec), np.round(cms_rawdataset.longitude.max().item(),n_dec)\n",
    "    lat_min, lat_max = np.round(cms_rawdataset.latitude.min().item(),n_dec),  np.round(cms_rawdataset.latitude.max().item(),n_dec)\n",
    "    lonmin_input = widgets.BoundedFloatText(description='Minimum:',value=lon_min,min=lon_min,max=lon_max,)\n",
    "    lonmax_input = widgets.BoundedFloatText(description='Maximum:',value=lon_max,min=lon_min,max=lon_max,)\n",
    "    latmin_input = widgets.BoundedFloatText(description='Minimum:',value=lat_min,min=lat_min,max=lat_max,)\n",
    "    latmax_input = widgets.BoundedFloatText(description='Maximum:',value=lat_max,min=lat_min,max=lat_max,)\n",
    "    # Display the widgets to select the region of interest\n",
    "    print('Longitude:')\n",
    "    display(widgets.VBox([lonmin_input, lonmax_input]))\n",
    "    print('Latitude:')\n",
    "    display(widgets.VBox([latmin_input, latmax_input]))\n",
    "elif boundary_dropdown.value == 'Pre-defined regions':\n",
    "    regions = sorted([os.path.basename(file).split('_region.nc')[0] for file in region_files])\n",
    "    print('Select the Pre-defined region:')\n",
    "    region_dropdown = widgets.Dropdown(options=regions, description='Region:', disabled=False)\n",
    "    display(region_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8249463-cc1c-469f-97fb-5a9a491139e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot selected region [not mandatory, just for visualization]\n",
    "projection = ccrs.PlateCarree()\n",
    "fig, axes  = plt.subplots(nrows=1,ncols=1,figsize=(10,6),subplot_kw={'projection': projection} )\n",
    "fig.subplots_adjust(bottom=0.02, top=0.92, left=0.02, right=0.87, wspace=0.05, hspace=0.05)\n",
    "axes._autoscaleXon = axes._autoscaleYon = False\n",
    "axes.coastlines()\n",
    "axes.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='black', facecolor='lightgrey'))\n",
    "axes.set_extent([lon_min, lon_max, lat_min, lat_max], crs=projection) # [west lon, east lon, south lat, north]\n",
    "gl = axes.gridlines(draw_labels=True, crs=ccrs.PlateCarree(), color='gray', linestyle='--', linewidth=0.2)\n",
    "gl.xlabel_style = gl.ylabel_style = {'size': 10, 'color': 'black'}\n",
    "gl.top_labels = gl.right_labels = False  # Disable top and right labels\n",
    "if filter_by_box:     # Add the box to the map\n",
    "    from matplotlib.patches import Rectangle\n",
    "    axes.set_title('Selected Box:\\nLons -> %s to %s\\nLats -> %s to %s'%(lonmin_input.value,lonmax_input.value,latmin_input.value,latmax_input.value))\n",
    "    axes.add_patch(Rectangle((lonmin_input.value, latmin_input.value),  # Lower-left corner\n",
    "                              lonmax_input.value - lonmin_input.value,  # Width\n",
    "                              latmax_input.value - latmin_input.value,  # Height\n",
    "                              linewidth=2, edgecolor='red', facecolor='none', transform=projection,zorder=10))\n",
    "else:                 # Open and add the region mask\n",
    "    axes.set_title('Selected region -> %s'%(region_dropdown.value))\n",
    "    reg_mask = xr.open_dataset(os.path.join(reg_path,\"MFS_CMS\",region_dropdown.value+'_region.nc'))\n",
    "    valid_points = reg_mask.where(reg_mask.index_region == 1, drop=True).stack(points=(\"lat\", \"lon\")).dropna(\"points\")\n",
    "    axes.scatter(valid_points.lon.values, valid_points.lat.values, color=\"steelblue\", transform=projection, label=\"Region Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26180931-2b74-460b-a491-8ea76879b6ff",
   "metadata": {},
   "source": [
    "### 3. Filtering and Processing the Datasets\n",
    "- Date and region of interest filters\n",
    "- Compute Anomaly and MHW mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02127395-b466-478e-8f0b-4e1bef1232ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_clim_date_range(ds, dates_list, time_dim=\"days\"):\n",
    "    \"\"\"\n",
    "    Extract a specific range of dates from a climatology dataset.\n",
    "    Parameters:\n",
    "    - ds (xr.Dataset or xr.DataArray): The input dataset or data array with time_dim dimensions or coordinates.\n",
    "    - dates_list (list of datetime): The list of the dates to extract\n",
    "    - time_dim (str): The name of the time dimension in the dataset.\n",
    "    Returns: The extracted subset of the dataset or data array as xr.Dataset or xr.DataArray.\n",
    "    \"\"\"\n",
    "    # Helper functions to calculate climatological day-of-year with adjust for leap years\n",
    "    def is_leap_year(year): return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n",
    "    \n",
    "    def to_climatological_day(date):\n",
    "        start_of_year = datetime(date.year, 1, 1)\n",
    "        current_date  = datetime(date.year, date.month, date.day)\n",
    "        dayofyear = (current_date - start_of_year).days\n",
    "        if date.month == 2 and date.day == 29:           dayofyear = 58 # If 29 Feb return 28 Feb dayofyear value\n",
    "        elif date.month > 2 and is_leap_year(date.year): dayofyear -= 1 # If leap year and date is after Feb 28, subtract one day\n",
    "        return dayofyear\n",
    "    \n",
    "    extracted_data = [ds.where(ds[time_dim] == to_climatological_day(date), drop=True) for date in dates_list]\n",
    "    result = xr.concat(extracted_data, dim=time_dim)\n",
    "    result = result.assign_coords({time_dim: dates_list})\n",
    "    return result\n",
    "\n",
    "def filter_box(ds, lon_min, lon_max, lat_min, lat_max, lon_var='lon',lat_var='lat', output=''):\n",
    "    \"\"\"\n",
    "    Filters an xarray dataset based on a bounding box of latitude and longitude.\n",
    "    Parameters:\n",
    "        ds (xarray.Dataset): The input dataset with 2D lat and lon coordinates.\n",
    "        lon_min,... (float): coordinates limits the bounding box.\n",
    "    Returns: The filtered xarray.Dataset.\n",
    "    \"\"\"\n",
    "    # Create a mask for the bounding box\n",
    "    mask = ((ds[lon_var] >= lon_min) & (ds[lon_var] <= lon_max) & (ds[lat_var] >= lat_min) & (ds[lat_var] <= lat_max))\n",
    "    if output == 'mask': return  mask.astype(int)#.broadcast_like(ds)\n",
    "    else: return ds.where(mask, drop=True)  # Apply the mask to the dataset and drop values outside the range\n",
    "\n",
    "def standardize_dim_names(ds, lat_name='latitude', lon_name='longitude', time_name='time'):\n",
    "    \"\"\"Standardize the dimension names of a dataset.\n",
    "    Parameters:\n",
    "    - ds (xarray.Dataset or xarray.DataArray): Input dataset or data array.\n",
    "    - *_name (str): standardized dimension name.\n",
    "    Returns: - xarray.Dataset or xarray.DataArray: Dataset with standardized dimension names.\n",
    "    \"\"\"\n",
    "    # Define a mapping of old dimension names to new ones\n",
    "    rename_map = {}\n",
    "    if 'latitude'    in ds.dims: rename_map['latitude']  = lat_name\n",
    "    elif 'Latitude'  in ds.dims: rename_map['Latitude']  = lat_name\n",
    "    elif 'lat'       in ds.dims: rename_map['lat']       = lat_name\n",
    "    if 'longitude'   in ds.dims: rename_map['longitude'] = lon_name\n",
    "    elif 'Longitude' in ds.dims: rename_map['Longitude'] = lon_name\n",
    "    elif 'lon'       in ds.dims: rename_map['lon']       = lon_name\n",
    "    if 'time'        in ds.dims: rename_map['time']      = time_name\n",
    "    elif 'days'      in ds.dims: rename_map['days']      = time_name\n",
    "    elif 'dayofyear' in ds.dims: rename_map['dayofyear'] = time_name\n",
    "    ds = ds.rename(rename_map) # Rename dimensions\n",
    "    if time_name in ds.dims: ds = ds.transpose(time_name, lat_name, lon_name)\n",
    "    else: ds = ds.transpose(lat_name, lon_name)\n",
    "    return ds\n",
    "\n",
    "def extract_TS(data,region,area):\n",
    "    region_3D = np.tile(region,(data.shape[0],1,1))\n",
    "    area_3D   = np.tile(area,(data.shape[0],1,1))\n",
    "    area_mask_3D = np.ma.masked_where(region_3D==0,area_3D)\n",
    "    data_mask    = np.ma.masked_where(region_3D==0,data)\n",
    "    data_mask    = np.ma.masked_where(np.isnan(data),data_mask)\n",
    "    data_mask    = np.ma.masked_where(data==0,data_mask)\n",
    "    area_mask_3D.mask = data_mask.mask # forcing nan mask of data_mask into area_mask_3D (necessary for box masks)\n",
    "    return np.sum(data_mask*area_mask_3D,axis=(1,2))/np.sum(area_mask_3D,axis=(1,2)) # calculates area-average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeca354-3d94-408f-80a9-cd865f6f25cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering and processing\n",
    "dataset_cms  = cms_rawdataset.copy()\n",
    "dataset_clim = clim_rawdataset.copy()\n",
    "cell_area      = area_rawdataset.cell_area\n",
    "cell_area_clim = area_clim_rawdataset.cell_area\n",
    "if 'depth' in dataset_cms.dims and dataset_cms.sizes['depth'] == 1: dataset_cms = dataset_cms.squeeze(dim='depth')\n",
    "\n",
    "print('Filtering...')\n",
    "print('\\tDates filter -> %s to %s (%s days)'%(date_start, date_end, (date_end-date_start).days))\n",
    "dates_list = [date_start + timedelta(days=i) for i in range((date_end - date_start).days + 1)]\n",
    "dataset_cms  = dataset_cms.sel({time_dim:slice(dates_list[0], dates_list[-1])}) # Date filter\n",
    "dataset_clim = extract_clim_date_range(dataset_clim, dates_list)\n",
    "#clim_ds = clim_ds.where(clim_ds != 9.96920997e+36, np.nan)\n",
    "\n",
    "if filter_by_box: \n",
    "    print('\\tBox filter   -> Lons [%s to %s] Lats [%s to %s]'%(lonmin_input.value,lonmax_input.value,latmin_input.value,latmax_input.value))\n",
    "    region_mask = region_mask_clim = filter_box(dataset_cms,lonmin_input.value,lonmax_input.value,latmin_input.value,latmax_input.value,lat_var='latitude',lon_var='longitude', output='mask')\n",
    "else:\n",
    "    region_name = region_dropdown.value\n",
    "    print('\\tRegion -> %s'%region_name)\n",
    "    region_mask   =  region_mask_clim = xr.open_dataset(os.path.join(reg_path,CMEMS_datasets_options[dataset_id]['region_folder'],region_name+'_region.nc')).index_region\n",
    "    if prod == 'MFS':region_mask_clim = xr.open_dataset(os.path.join(reg_path,'MFS',region_name+'_region.nc')).index_region # climatology and MFS on different grids\n",
    "\n",
    "# Standardize coordinates (lat,lon) dimensions names \n",
    "dataset_cms = standardize_dim_names(dataset_cms)\n",
    "region_mask = standardize_dim_names(region_mask)\n",
    "cell_area   = standardize_dim_names(cell_area)\n",
    "dataset_clim     = standardize_dim_names(dataset_clim)\n",
    "region_mask_clim = standardize_dim_names(region_mask_clim)\n",
    "cell_area_clim   = standardize_dim_names(cell_area_clim)  \n",
    "# extract_TS for each variable of the datasets\n",
    "print('Applying masks and computing area-average...')\n",
    "t0=time.time()\n",
    "averaged_vars = {}\n",
    "print('\\tCMEMS data...')\n",
    "for var_name, var_data in dataset_cms.data_vars.items():\n",
    "    if var_data.min() > 100: var_data = var_data - 273.15  # Kelvin units check\n",
    "    averaged_vars[var_name] = xr.DataArray(extract_TS(var_data, region_mask, cell_area), \n",
    "                                            dims=[time_dim], coords={time_dim: var_data[time_dim]},name=var_name)\n",
    "print('\\tCLIM data...')\n",
    "for var_name, var_data in dataset_clim.data_vars.items():\n",
    "    if var_data.min() > 100: var_data = var_data - 273.15  # Kelvin units check\n",
    "    averaged_vars[var_name] = xr.DataArray(extract_TS(var_data, region_mask_clim, cell_area_clim), \n",
    "                                            dims=[time_dim], coords={time_dim: var_data[time_dim]},name=var_name)\n",
    "print('\\tElapsed time: %ss'%(round(time.time()-t0,1)))\n",
    "processed_dataset = xr.Dataset(averaged_vars) # Combine all variables into a single dataset\n",
    "print('Detecting Marine HeatSpikes (MHS) and Marine HeatWaves (MHW)...')\n",
    "t0=time.time()\n",
    "MHS, MHW = wns(processed_dataset[varname].values, processed_dataset.pc90.values)\n",
    "processed_dataset['MHS'] = xr.DataArray(MHS, dims=processed_dataset[varname].dims,  coords=processed_dataset[varname].coords)\n",
    "processed_dataset['MHW'] = xr.DataArray(MHW, dims=processed_dataset[varname].dims,  coords=processed_dataset[varname].coords)\n",
    "print('\\tElapsed time: %ss'%(round(time.time()-t0,1)))\n",
    "daterange_str = '%s_to_%s'%(str(date_start).replace('-', ''), str(date_end).replace('-', ''))\n",
    "if filter_by_box: region_str = 'box[Lon%sto%s][Lat%sto%s]'%(lonmin_input.value,lonmax_input.value,latmin_input.value,latmax_input.value)\n",
    "else: region_str = region_name\n",
    "# out_filename = \"MHWtimeseries_CMEMS_%s_%s_%s.nc\"%(prod,daterange_str,region_str)\n",
    "out_filename = \"test.nc\"\n",
    "output_file = os.path.join(out_dir,out_filename)\n",
    "processed_dataset.to_netcdf(output_file)\n",
    "print(f\"\\tNetCDF file saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2d57a-5b28-4c2c-8d99-f2aaeaf5098f",
   "metadata": {},
   "source": [
    "### 4. TimeSeries plot\n",
    "- SST climatology, 90th percentile and daily area-averaged data from CMEMS product\n",
    "- Filled area for detected MHS (yellow) and MHW (orange)\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d236203-bc4a-4f2b-b1c9-395c4ec31d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PLOTTING\n",
    "figname = 'MHW_timeseries_%s_%s_%s.png'%(prod,daterange_str,region_str)\n",
    "\n",
    "#figsize = (8,4.5)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "fig.subplots_adjust(bottom=0.1, top=0.92, left=0.1, right=0.98, wspace=0.1, hspace=0.1)\n",
    "ax.set_title(\"Marine Heat Waves\\n%s\\n%s\"%(dataset_id,region_str),fontweight='bold')\n",
    "xrange=(date_start,date_end)\n",
    "\n",
    "ax.grid(alpha=0.6)\n",
    "ax.plot(processed_dataset[time_dim],processed_dataset[varname],'-',color='darkgrey',lw=3,label=\"CMEMS data\")\n",
    "ax.plot(processed_dataset[time_dim],processed_dataset.pc90,'--',color='darkred',label=\"MHW Threshold\")\n",
    "ax.plot(processed_dataset[time_dim],processed_dataset.clim,'-',color='darkred',label=\"Average 1987-2021\")\n",
    "    \n",
    "ax.fill_between(processed_dataset[time_dim],processed_dataset.pc90,processed_dataset[varname],where=processed_dataset['MHS'],color='yellow')\n",
    "ax.fill_between(processed_dataset[time_dim],processed_dataset.pc90,processed_dataset[varname],where=processed_dataset['MHW'],color='orange')\n",
    "\n",
    "ax.set_ylabel(\"Temperature ($^{o}C)$\")\n",
    "ax.set_xlim(xrange)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=8))\n",
    "\n",
    "ax.legend(loc=\"lower center\",bbox_to_anchor=(.5, -.2), ncol=3)\n",
    "fig.tight_layout()\n",
    "fig.savefig(output_file.replace('.nc','.png'),dpi=300)\n",
    "print(f\"\\tPNG figure saved at '{output_file.replace('.nc','.png')}'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3cc9d-478a-44f3-b64a-a440c805822f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040210f3-4f92-412e-8624-92ef3d77e42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
